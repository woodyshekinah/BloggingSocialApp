{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install replicate\n",
    "%pip install pypdf\n",
    "%pip install langchain==0.2.0\n",
    "%pip install langchain-pinecone==0.0.7\n",
    "%pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Trial file\\.venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import replicate\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community .llms import CTransformers\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"c85a2244-4db3-464b-a9e2-f366e296718d\"\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):    \n",
    "        loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader)\n",
    "        \n",
    "        documents = loader.load()\n",
    "        return documents\n",
    "        print(documents)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 1911\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the Pinecone\n",
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "os.environ['PINECONE_API_KEY']= 'c85a2244-4db3-464b-a9e2-f366e296718d'\n",
    "\n",
    "pinecone.instance = Pinecone(api_key='c85a2244-4db3-464b-a9e2-f366e296718d',environment='us-east-1')\n",
    "\n",
    "index_name=\"graduating-project\"\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "#Creating Embeddings for Each of The Text Chunks & storing\n",
    "docsearch = PineconeVectorStore.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content='One fina l important bit of advice : Remember to pass on what you know to a\\nfuture sm all farm er . T eaching others is also a great way of reinf orcing what\\nyou kno w . By being honest about the joys and pitfalls of farmi ng, you can\\nmentor others about the wonderful world of small-scale farming.\\nT able of Contents'), Document(page_content='clearly\\tmakes\\tsense\\tand\\tis\\tworth\\trepeating—go\\tand\\twork\\ton\\ta\\tfarm.\\tTry\\tout\\nthe\\tidea\\tby\\tlaboring\\t(and\\tlearning)\\twith\\tsomeone\\telse.\\tExperience\\tthe\\tgood\\ntimes\\tand\\tthe\\tbad,\\tthe\\trealities\\tand\\tthe\\trewards.\\tIf\\tpossible,\\twork\\ton\\tmore\\nthan\\tone\\tfarm.\\tThe\\tmore\\tbackground\\tand\\texperience\\tyou\\tcan\\tget,\\tthe\\tbetter\\noff\\tyou’ll\\tbe.\\nThe\\trequirements\\tfor\\tsuccess\\tin\\tfarming\\tare\\tlike\\tthose\\tfor\\tany\\tsmall\\nbusiness:\\torganizational\\taptitude,\\tdiligence,\\tfinancial\\tplanning,\\tthe\\tability\\tto'), Document(page_content='the\\toperation\\tshould\\tspend\\this\\tor\\ther\\ttime\\tdoing\\tthat\\tas\\twell\\tas\\tit\\tcan\\tbe\\tdone.\\nOverall\\tefficiency\\twill\\tbe\\tgreater.\\tHire\\tlabor\\tto\\tcomplement\\trather\\tthan\\nreplace\\tfamily\\tskills.\\nBe\\tflexible.\\tWork\\tout\\ta\\tsolution\\tfor\\tthe\\tparticular\\tlabor\\tneeds\\tof\\tthe\\nmoment.\\tIf\\tthe\\tlabor\\tarrangement\\tof\\tthe\\tfarm\\tdoes\\tnot\\tparallel\\tthat\\tof\\tmodern\\nagriculture,\\tlet\\tit\\tbe\\tof\\tno\\tconcern.\\tMany\\tunique\\tsituations\\tare\\tsuccessful.\\tA\\nfarm\\tmay\\tbe\\tnext\\tdoor\\tto\\ta\\tlarge\\tvegetarian\\tcommunity\\tthat\\twill\\tbuy')]\n"
     ]
    }
   ],
   "source": [
    "#If we already have an index we can load it like this\n",
    "docsearch=PineconeVectorStore.from_existing_index(index_name, embeddings)\n",
    "\n",
    "query = \"How to manage a farm\"\n",
    "\n",
    "docs=docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content='A few of the recipes in this book call for specialty flours like almond,\\nwhole wheat, and spelt. Luckily , these can now be found fairly easily at\\nregular grocery stores. They add an extra element of flavor and/or texture,\\nbut can usually be substituted.\\nTo meas ure flour, use the scoop-and-sweep method. First, aerate the\\nflour in its container by briefly mixing the contents with a whisk. Then\\nscoop flour into the measuring cup until it is slightly overflowing. Level off'), Document(page_content='westelm.com\\nBaking tools, dinnerware, flatware, linens, and more\\nWhole Foods Market:\\nwholefoodsmarket.com\\nOrganic and specialty foods\\nWilliams-Sonoma:\\nwilliams-sonoma.com\\nEquipment, baking tools, cake pans, and some specialty foods'), Document(page_content='British India, described it as “the embodiment of all things pure.”')]\n"
     ]
    }
   ],
   "source": [
    "def load_pinecone_existing_index():\n",
    "    docsearch = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "    return docsearch\n",
    "docsearch=load_pinecone_existing_index()\n",
    "\n",
    "query = \"How to manage a farm\"\n",
    "\n",
    "docs=docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4002402046.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[41], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    llm =\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Replicate\n",
    "os.environ['REPLICATE_API_TOKEN']=\"r8_YgNQpNUeSV2XL230IieDlrWC1YU0KFR3eQjJz\"\n",
    "llm = Replicate(model)\n",
    "# llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "#                   model_type=\"llama\",\n",
    "#                   config={'max_new_tokens':512,\n",
    "#                           'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['PineconeVectorStore', 'HuggingFaceEmbeddings'] vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x000001C6918C60F0> search_kwargs={'k': 2}\n"
     ]
    }
   ],
   "source": [
    "retriever=docsearch.as_retriever(search_kwargs={'k': 2})\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
